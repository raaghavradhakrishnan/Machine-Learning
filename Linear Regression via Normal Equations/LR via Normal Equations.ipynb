{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1.2 Linear Regression via Normal Equations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Importing the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.linalg\n",
    "import random\n",
    "import math\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function Name: Create_data\n",
    "### Parameter: Filename\n",
    "This function reads the data, shuffles them and split it to input variables and target values\n",
    "\n",
    "After analysing the Mean Square error with differernt input variables, price,income,gasolines and pumps are taken into account. Also, the variables namely CarWash, Competitors, Zipcode, Address, ID, Restaurant does not play a major role as it can be seen in the data file. And when we analyse the top 10 incomes, we get to see that location of the station i.e., highways, intersection influences the income but as the error increases when we use them, they are also neglected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data(filename):\n",
    "    Data = pd.read_csv(filename)\n",
    "    Req_Data = Data.drop(columns = ['Unnamed: 0','ID','Restaurant',\n",
    "                                    'CarWash','Competitors','Zipcode','Address'\n",
    "                                     ,'Highway','IntersectionStoplight','Name','Stoplight'\n",
    "                                   ,'Interior','Intersection','Brand'])\n",
    "    Shuffle_data = Req_Data.sample(frac = 1)\n",
    "    Shuffle_data = pd.get_dummies(Shuffle_data)\n",
    "    Y_data = Shuffle_data.Income/np.linalg.norm(Shuffle_data.Income)\n",
    "    #Y_data = Shuffle_data.Income\n",
    "    X_data = Shuffle_data.drop(columns = ['Income'])\n",
    "    X_data = X_data.values\n",
    "    return X_data,Y_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function Name: create_Test_Train_data\n",
    "### Parameter: Data of input variables and target\n",
    "This function splits the input variables and target data to Train and Test data with 80% and 20% of the data respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_Test_Train_data(X_data,Y_data):\n",
    "    Y_train = Y_data[:math.ceil(0.8*len(Y_data))]\n",
    "    Y_test = Y_data[math.ceil(0.8*len(Y_data)):]\n",
    "    X_train = X_data[:math.ceil(0.8*len(X_data))]\n",
    "    X_test = X_data[math.ceil(0.8*len(X_data)):]\n",
    "    X = np.ones((X_train.shape[0],X_train.shape[1]+1))\n",
    "    X[:,1:] = X_train\n",
    "    A = np.dot(X.T,X)\n",
    "    B = np.dot(X.T,Y_train)\n",
    "    return Y_train,Y_test,X_train,X_test,A,B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function Name: slv_beta    \n",
    "### Parameter: Input variables matrix and Target vector\n",
    "This function returns the set of parameters trained from the input variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slv_beta(A,B):\n",
    "    b = np.linalg.solve(A,B)\n",
    "    return b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function Name: Predict\n",
    "### Parameter: Parameter vector\n",
    "This function predicts the target value for the test data and returns the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Predict(b):\n",
    "    Test = np.ones((X_test.shape[0],X_test.shape[1]+1))\n",
    "    Test[:,1:] = X_test\n",
    "    Pred_Y_test = np.matmul(Test,b)\n",
    "    return Pred_Y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function Name: MSE_Plot\n",
    "### Parameter: Predicted vector\n",
    "This function calculates the Root Mean Square Error for the data predicted by the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSE_Plot(Pred_Y_test):\n",
    "    total = 0\n",
    "    for i in range(0,len(Y_test)):\n",
    "        total+=pow(Pred_Y_test[i]-Y_test.values[i],2)\n",
    "    print(\"\\nMSE:     \",total/len(Y_test))\n",
    "    plt.plot(Y_test.values,\"bo\")\n",
    "    plt.plot(Pred_Y_test,\"ro\")\n",
    "    plt.xlabel(\"Value\")\n",
    "    plt.ylabel(\"Test and Prediction\")\n",
    "    plt.show()\n",
    "    return RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function Name: cholesky_matrix\n",
    "### Parameter: Input variables matrix\n",
    "This function does operations within the matrix and returns the Lower Triangular Matrix to perform backward substitution process for getting the set of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cholesky_matrix(A):\n",
    "    \n",
    "    if A.shape[0] == A.shape[1]:\n",
    "        A = A.astype(float)\n",
    "        L = np.zeros_like(A)\n",
    "        size = np.size(A, 0)\n",
    "        L[0, 0] = pow(A[0, 0],0.5)\n",
    "        for i in range(1, size):\n",
    "            L[i:, i-1] = (A[i:, i-1] - L[i:, :i-1].dot(L[i-1, :i-1])) / L[i-1, i-1]\n",
    "            L[i, i] = pow((A[i, i] - L[i, :i].dot(L[i, :i])),0.5)\n",
    "        return L\n",
    "    \n",
    "    else:\n",
    "        print (\"Invalid Matrix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function Name: gauss_beta\n",
    "### Parameter: Input variables matrix and Target vector\n",
    "\n",
    "This function solves the set of linear equation returns the set of parameters trained from the input variables using Gaussian elimination method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gauss_beta(A,B):\n",
    "    if A.shape[0] == A.shape[1]:\n",
    "        Gauss_mat = np.ones((A.shape[0],A.shape[1]+1))\n",
    "        Gauss_mat[:,:A.shape[0]] = A[:,:A.shape[0]]\n",
    "        Gauss_mat[:,A.shape[0]] = B\n",
    "        A = Gauss_mat\n",
    "        n = len(A)\n",
    "        for i in range(0, n):\n",
    "            # Search for maximum in this column\n",
    "            maxEl = abs(A[i][i])\n",
    "            maxRow = i\n",
    "            for k in range(i+1, n):\n",
    "                if abs(A[k][i]) > maxEl:\n",
    "                    maxEl = abs(A[k][i])\n",
    "                    maxRow = k\n",
    "            # Swap maximum row with current row (column by column)\n",
    "            for k in range(i, n+1):\n",
    "                tmp = A[maxRow][k]\n",
    "                A[maxRow][k] = A[i][k]\n",
    "                A[i][k] = tmp\n",
    "\n",
    "            # Make all rows below this one 0 in current column\n",
    "            for k in range(i+1, n):\n",
    "                c = -A[k][i]/A[i][i]\n",
    "                for j in range(i, n+1):\n",
    "                    if i == j:\n",
    "                        A[k][j] = 0\n",
    "                    else:\n",
    "                        A[k][j] += c * A[i][j]\n",
    "\n",
    "        # Solve equation Ax=b for an upper triangular matrix A\n",
    "        x = [0 for i in range(n)]\n",
    "        for i in range(n-1, -1, -1):\n",
    "            x[i] = A[i][n]/A[i][i]\n",
    "            for k in range(i-1, -1, -1):\n",
    "                A[k][n] -= A[k][i] * x[i]\n",
    "        return x\n",
    "    \n",
    "    else:\n",
    "        print (\"Invalid Matrix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function Name: forward_substitution and backward_substitution\n",
    "### Parameter: Input variables matrix and Target vector\n",
    "These functions performs the forward and backward substitutions for the lower triangle and upper triangle matrix respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_substitution(A, B):\n",
    "    \n",
    "    if A.shape[0] == A.shape[1]:\n",
    "        x = np.zeros_like(B)\n",
    "        for i in range(np.size(x, 0)):\n",
    "            x[i] = (B[i] - A[i, :i].dot(x[:i])) / A[i, i]\n",
    "        return x\n",
    "\n",
    "    else:\n",
    "        print (\"Invalid Matrix\")\n",
    "        \n",
    "def backward_substitution(A, B):\n",
    "    \n",
    "    if A.shape[0] == A.shape[1]:\n",
    "        x = np.zeros_like(B)\n",
    "        for i in range(np.size(x, 0)).__reversed__():\n",
    "            x[i] = (B[i] - A[i, i+1:].dot(x[i+1:])) / A[i, i]\n",
    "        return x\n",
    "    \n",
    "    else:\n",
    "        print (\"Invalid Matrix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function Name: QR_beta\n",
    "### Parameter: Input variables matrix and Target vector\n",
    "\n",
    "This function solves the set of linear equation returns the set of parameters trained from the input variables using QR decomposition method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def QR_beta(A,B):\n",
    "    Q,R = np.linalg.qr(A)\n",
    "    dot_QB = np.dot(Q.T,B)\n",
    "    b = backward_substitution(R,dot_QB)\n",
    "    return b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function Name: linalg_slv\n",
    "### Parameter: Input variables matrix and Target vector\n",
    "\n",
    "This function solves the set of linear equation using normal equations. From the learned set of parameters, the target data is predicted from the model and the error is computed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linalg_slv(A,B):\n",
    "    if A.shape[0] == A.shape[1]:\n",
    "        b = slv_beta(A,B)\n",
    "        print(\"Solving linear equations using Normal equations:\\n\")\n",
    "        print(\"Set of Parameters:\\n\",b)\n",
    "        Pred_Y_test = Predict(b)\n",
    "        RMSE = RMSE_Plot(Pred_Y_test)\n",
    "        return Pred_Y_test\n",
    "        \n",
    "    else:\n",
    "        print (\"Invalid Matrix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function Name: gaussian_elimination\n",
    "### Parameter: Input variables matrix and Target vector\n",
    "\n",
    "This function solves the set of linear equation using Gaussian elimination method. From the learned set of parameters, the target data is predicted from the model and the error is computed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_elimination(A,B):\n",
    "    b = gauss_beta(A,B)\n",
    "    print(\"Solving linear equations using Gaussian elimination:\\n\")\n",
    "    print(\"Set of Parameters:\\n\",b)\n",
    "    Pred_Y_test = Predict(b)\n",
    "    RMSE = RMSE_Plot(Pred_Y_test)\n",
    "    return Pred_Y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function Name: cholesky_decomposition\n",
    "### Parameter: Input variables matrix and Target vector\n",
    "\n",
    "This function solves the set of linear equation using Cholesky decomposition method. From the learned set of parameters, the target data is predicted from the model and the error is computed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cholesky_decomposition(A,B):\n",
    "    mat_cholesky= cholesky_matrix(A)\n",
    "    y = forward_substitution(mat_cholesky,B)\n",
    "    y=np.array(y)\n",
    "    b = backward_substitution(mat_cholesky.T,y)\n",
    "    print(\"Solving linear equations using Cholesky Decomposition:\\n\")\n",
    "    print(\"Set of Parameters: \\n\",b)\n",
    "    Pred_Y_test = Predict(b)\n",
    "    RMSE = RMSE_Plot(Pred_Y_test)\n",
    "    return Pred_Y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function Name: QR_decomposition\n",
    "### Parameter: Input variables matrix and Target vector\n",
    "\n",
    "This function solves the set of linear equation using QR decomposition method. From the learned set of parameters, the target data is predicted from the model and the error is computed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def QR_decomposition(A,B):\n",
    "    b = QR_beta(A,B)\n",
    "    print(\"Solving linear equations using QR Decomposition:\\n\")\n",
    "    print(\"Set of Parameters:\\n\",b)\n",
    "    Pred_Y_test = Predict(b)\n",
    "    RMSE = RMSE_Plot(Pred_Y_test)\n",
    "    return Pred_Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSE(Predicted,Y_test):\n",
    "    return np.sqrt(np.sum(pow(Y_test - np.mean(Predicted),2))/len(Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main function to call other functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    filename = \"GasPrices.csv\"\n",
    "    X_data,Y_data = create_data(filename)\n",
    "    Y_train,Y_test,X_train,X_test,A,B = create_Test_Train_data(X_data,Y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Pred_slv = linalg_slv(A,B)    \n",
    "residual_slv  = abs(Y_test.values - np.mean(Pred_slv))\n",
    "print(\"\\nAverage Residual: \",np.average(residual_slv))\n",
    "print(\"\\nRMSE : \",round(RMSE(residual_slv,Y_test),5))\n",
    "plt.plot(residual_slv ,Y_test,'ro')\n",
    "plt.xlabel(\"Residual\")\n",
    "plt.ylabel(\"Test data\")\n",
    "plt.title(\"Residual vs Test data (Normal Equations)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pred_ge = gaussian_elimination(A,B)\n",
    "residual_ge = abs(Y_test.values - np.mean(Pred_ge))\n",
    "print(\"\\nAverage Residual: \",np.average(residual_ge))\n",
    "print(\"\\nRMSE : \",round(RMSE(residual_ge,Y_test),5))\n",
    "plt.plot(residual_ge ,Y_test,'bo')\n",
    "plt.xlabel(\"Residual\")\n",
    "plt.ylabel(\"Test data\")\n",
    "plt.title(\"Residual vs Test data (Gaussian Elimination)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pred_qr = QR_decomposition(A,B)\n",
    "residual_qr = abs(Y_test.values - np.mean(Pred_qr))\n",
    "print(\"\\nAverage Residual: \",np.average(residual_qr))\n",
    "print(\"\\nRMSE : \",round(RMSE(residual_qr,Y_test),5))\n",
    "plt.plot(residual_qr ,Y_test,'go')\n",
    "plt.xlabel(\"Residual\")\n",
    "plt.ylabel(\"Test data\")\n",
    "plt.title(\"Residual vs Test data (QR Decomposition)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pred_cholesky = cholesky_decomposition(A,B)\n",
    "residual_cholesky = abs(Y_test.values - np.mean(Pred_cholesky))\n",
    "print(\"\\nAverage Residual: \",np.average(residual_cholesky))\n",
    "print(\"\\nRMSE : \",round(RMSE(residual_cholesky,Y_test),5))\n",
    "plt.plot(residual_cholesky ,Y_test,'yo')\n",
    "plt.xlabel(\"Residual\")\n",
    "plt.ylabel(\"Test data\")\n",
    "plt.title(\"Residual vs Test data (Cholesky Decomposition)\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
